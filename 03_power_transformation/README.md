# Power Transformation

## Overview

Power transformation techniques are used to stabilize variance, reduce skewness, and make numerical data more normally distributed.

Many machine learning algorithms perform better when features follow a Gaussian-like distribution. Power transformations help reshape skewed data into a more symmetric form.

---

## Why It Matters

- Reduces skewness  
- Improves model performance  
- Stabilizes variance  
- Helps linear and distance-based models  

---

## Techniques Covered

- Log Transformation  
- Box-Cox Transformation  
- Yeo-Johnson Transformation  

---

## Key Idea

Transform the feature distribution while preserving the relative order of values.